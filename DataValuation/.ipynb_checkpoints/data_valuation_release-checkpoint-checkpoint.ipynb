{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fph7oHL6qEDd"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Flatten, Dense, LeakyReLU, Dropout\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.special import comb\n",
    "import itertools\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from cvxopt import matrix, solvers, spdiag\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0DlmQMgr3ce"
   },
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxcxQQresFFI"
   },
   "source": [
    "## Least Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h561ROJ0r22c"
   },
   "outputs": [],
   "source": [
    "def checkConstraint(A, x, e, utility):\n",
    "    check = np.round(np.matmul(A, x)+e, 5) >= np.round(utility, 5)\n",
    "    print('Total Constraints: %s, Satisfy: %s, Accuracy: %s' % (len(check), sum(check), sum(check)/len(check)))\n",
    "\n",
    "def ComputeLC(X_feature, y_feature, u_tot):\n",
    "    t, N = np.array(X_feature).shape\n",
    "    X_feature_new = np.hstack((X_feature, np.ones((len(y_feature), 1))))\n",
    "\n",
    "    c = matrix([0]*N+[1.0], (N+1,1), 'd')\n",
    "    G = matrix(-X_feature_new, (len(y_feature), N+1), 'd' )\n",
    "    h = matrix(-np.array(y_feature), (len(y_feature), 1), 'd')\n",
    "    A = matrix([1.0]*N+[0], (1, N+1), 'd')\n",
    "    b = matrix([u_tot], (1, 1), 'd')\n",
    "\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.lp(c, G, h, A, b)\n",
    "    print(sol['status'])\n",
    "    # print(sol['x'])\n",
    "\n",
    "    x = np.array(sol['x']).reshape(len(sol['x']))[:N]\n",
    "    e = np.array(sol['x']).reshape(len(sol['x']))[-1]\n",
    "\n",
    "    return x, e\n",
    "\n",
    "def ComputeLC_Normalize(X_feature, y_feature, u_tot, e):\n",
    "    t, N = np.array(X_feature).shape\n",
    "\n",
    "    Q = 2*matrix(np.eye(N), (N, N), 'd')\n",
    "    p = matrix(np.zeros(N), (N, 1), 'd')\n",
    "\n",
    "    G = matrix(-np.array(X_feature), (len(y_feature), N), 'd' )\n",
    "    h = matrix(-np.array(y_feature)+e, (len(y_feature), 1), 'd')\n",
    "    A = matrix([1.0]*N, (1, N), 'd')\n",
    "    b = matrix([u_tot], (1, 1), 'd')\n",
    "\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.qp(Q, p, G, h, A, b)\n",
    "    print(sol['status'])\n",
    "\n",
    "    x = np.array(sol['x']).reshape(len(sol['x']))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyOAtKrOsGYo"
   },
   "source": [
    "## Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NXfAdLfdsHAg"
   },
   "outputs": [],
   "source": [
    "def val_to_dataind(v):\n",
    "    # 利用二进制来选择所有的子集\n",
    "    one_hot = np.array([int(x) for x in bin(v)[2:]])[::-1]\n",
    "    return one_hot.nonzero()[0]\n",
    "\n",
    "def dataind_to_val(arr):\n",
    "    val = 0\n",
    "    for i in arr:\n",
    "        val += 2**i\n",
    "    return val\n",
    "\n",
    "def exact_shapley(utility_array, n_data, target_ind):\n",
    "    sv = 0\n",
    "    for v in range(0, 2**n_data):\n",
    "        ind_set = val_to_dataind(v)\n",
    "        if target_ind in ind_set:\n",
    "            pass\n",
    "        else:\n",
    "            s = len(ind_set)\n",
    "            weight = 1/n_data * (1/comb(n_data-1, s))\n",
    "            v_sand = dataind_to_val(list(ind_set)+[target_ind])\n",
    "            sv += weight*(utility_array[v_sand] - utility_array[v])\n",
    "    return sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P5hyah1-sauw"
   },
   "outputs": [],
   "source": [
    "def perm_shapley_exact(utility_array, n_data, target_ind):\n",
    "    marginal_value = []\n",
    "    for perm in itertools.permutations(range(n_data)):\n",
    "        i = perm.index(target_ind)\n",
    "        team_without = list(perm[:i])\n",
    "        without_score = utility_array[int(dataind_to_val(team_without))]\n",
    "\n",
    "        team_with = list(perm[:i+1])\n",
    "        with_score = utility_array[int(dataind_to_val(team_with))]\n",
    "        marginal_value.append(with_score - without_score)\n",
    "    return np.average(marginal_value)\n",
    "\n",
    "def perm_shapley_sampling(utility_array, n_data, target_ind, n_sample):\n",
    "    marginal_value = []\n",
    "    n_sample = int(n_sample / 2)\n",
    "\n",
    "    X_feature, y_feature = [], []\n",
    "\n",
    "    for _ in range(n_sample):\n",
    "        perm = np.random.permutation(range(n_data))\n",
    "\n",
    "        i = (perm==target_ind).nonzero()[0][0]\n",
    "\n",
    "        team_without = list(perm[:i])\n",
    "        v_without = int(dataind_to_val(team_without))\n",
    "        without_score = utility_array[v_without]\n",
    "        y_feature.append(without_score)\n",
    "        ind_bin = -np.ones(n_data)\n",
    "        ind_bin[val_to_dataind(v_without)] = 1\n",
    "        X_feature.append(ind_bin)\n",
    "\n",
    "        team_with = list(perm[:i+1])\n",
    "        v_with = int(dataind_to_val(team_with))\n",
    "        with_score = utility_array[v_with]\n",
    "        y_feature.append(with_score)\n",
    "        ind_bin = -np.ones(n_data)\n",
    "        ind_bin[val_to_dataind(v_with)] = 1\n",
    "        X_feature.append(ind_bin)\n",
    "\n",
    "        marginal_value.append(with_score - without_score)\n",
    "    return np.average(marginal_value), X_feature, y_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4uM_41MGsemt"
   },
   "outputs": [],
   "source": [
    "def grouptest_shapley_sampling(utility_array, n_data, n_sample):\n",
    "    N = n_data\n",
    "    Z = 2*np.sum([1/i for i in range(1, N)])\n",
    "    q = [1/Z * (1/k + 1/(N-k)) for k in range(1, N)]\n",
    "    u_tot = utility_array[-1]\n",
    "\n",
    "    T = int(n_sample / 2)\n",
    "\n",
    "    A = np.zeros((T, n_data))\n",
    "    B = np.zeros(T)\n",
    "\n",
    "    X_feature, y_feature = [], []\n",
    "\n",
    "    for t in range(T):\n",
    "        # Randomly sample size from 1,...,N-1\n",
    "        num_sample_users = np.random.choice(np.arange(1, N), p=q)\n",
    "\n",
    "        # Uniformly sample kt data points from N data points\n",
    "        sampled_data_ind = np.random.choice(np.arange(N), num_sample_users, replace=False)\n",
    "\n",
    "        A[t, sampled_data_ind] = 1\n",
    "        v = int(dataind_to_val(sampled_data_ind))\n",
    "        B[t] = utility_array[v]\n",
    "\n",
    "        y_feature.append(utility_array[v])\n",
    "        ind_bin = -np.ones(n_data)\n",
    "        ind_bin[val_to_dataind(v)] = 1\n",
    "        X_feature.append(ind_bin)\n",
    "\n",
    "    C = {}\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            C[(i,j)] = Z/T*(B.dot(A[:,i] - A[:,j]))\n",
    "\n",
    "    sv_last, x, y = perm_shapley_sampling(utility_array, n_data, n_data-1, T)\n",
    "    X_feature += x\n",
    "    y_feature += y\n",
    "\n",
    "    sv_approx = np.zeros(N)\n",
    "    for i in range(N-1):\n",
    "        sv_approx[i] = C[(i, N-1)] + sv_last\n",
    "    sv_approx[N-1] = sv_last\n",
    "  \n",
    "    return sv_approx, X_feature, y_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK7aqmDrspIm"
   },
   "source": [
    "# Utility Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HSvJpAlksqEd"
   },
   "outputs": [],
   "source": [
    "def sample_utility(n, size_min, size_max, x_train, y_train, utility_func, random_state, verbose=False):\n",
    "\n",
    "    X_feature_test = []\n",
    "    y_feature_test = []\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    N = len(y_train)\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    for i in range(n):\n",
    "        if verbose:\n",
    "            print('{} / {}'.format(i, n))\n",
    "        n_select = np.random.choice(range(size_min, size_max))\n",
    "        subset_index = np.random.choice(range(N), n_select, replace=False)\n",
    "\n",
    "        y_subset = y_train[subset_index]\n",
    "\n",
    "        if np.count_nonzero(y_subset == y_subset[0]) == len(y_subset):\n",
    "            y_feature_test.append(np.sum(y_train) / N)\n",
    "        else:\n",
    "            y_feature_test.append(utility_func(\n",
    "                x_train[subset_index], y_train[subset_index]))\n",
    "\n",
    "        temp = np.zeros(N)\n",
    "        temp[subset_index] = 1\n",
    "        X_feature_test.append(temp)\n",
    "\n",
    "    return X_feature_test, y_feature_test\n",
    "\n",
    "\n",
    "def sample_learned_utility(n, size_min, size_max, x_train, y_train, model, random_state):\n",
    "    X_feature_test = []\n",
    "    y_feature_test = []\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    N = len(y_train)\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    for _ in range(n):\n",
    "        n_select = np.random.choice(range(size_min, size_max))\n",
    "        subset_index = np.random.choice(range(N), n_select, replace=False)\n",
    "\n",
    "        y_subset = y_train[subset_index]\n",
    "\n",
    "        temp = np.zeros(N)\n",
    "        temp[subset_index] = 1\n",
    "        X_feature_test.append(temp)\n",
    "\n",
    "        if np.count_nonzero(y_subset == y_subset[0]) == len(y_subset):\n",
    "            y_feature_test.append(np.sum(y_train) / N)\n",
    "        else:\n",
    "            y_feature_test.append(model.predict(\n",
    "                np.array(temp.reshape(1, temp.size, 1)))[0][0])\n",
    "\n",
    "    return np.array(X_feature_test), np.array(y_feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vsN2shW3tEex"
   },
   "outputs": [],
   "source": [
    "class UtilityModel:\n",
    "\n",
    "    def __init__(self, dataset_name, load_name=None):\n",
    "        if dataset_name == 'Synthetic':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Flatten(input_shape=(200, 1)))\n",
    "            model.add(Dense(512, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(256, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(32, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "            if load_name:\n",
    "                model.load_weights(load_name)\n",
    "\n",
    "        elif dataset_name == 'UCI_Congress':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Flatten(input_shape=(N, 1)))\n",
    "            model.add(Dense(2*N, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(256, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(128, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(32, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "            model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "        elif dataset_name == 'mini':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Flatten(input_shape=(10, 1)))\n",
    "            model.add(Dense(200, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(50, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "            if load_name:\n",
    "                model.load_weights(load_name)\n",
    "\n",
    "        elif dataset_name == 'mini-iris':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Flatten(input_shape=(15, 1)))\n",
    "            model.add(Dense(200, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(100, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(50, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "            if load_name:\n",
    "                model.load_weights(load_name)\n",
    "\n",
    "        elif dataset_name == 'mini_overfit':\n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Flatten(input_shape=(10, 1)))\n",
    "            model.add(Dense(200, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(100, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(50, activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "            if load_name:\n",
    "                model.load_weights(load_name)\n",
    "\n",
    "        else:\n",
    "            print('dataset not support!')\n",
    "            exit(1)\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X_feature, y_feature, X_feature_test, y_feature_test,\n",
    "            lr,\n",
    "            save_name=None, verbose=0, epoch=100, batch_size=32, callback=None):\n",
    "\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        self.model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "\n",
    "        X_feature = np.array(X_feature)\n",
    "        y_feature = np.array(y_feature)\n",
    "        X_feature_test = np.array(X_feature_test)\n",
    "        y_feature_test = np.array(y_feature_test)\n",
    "\n",
    "        if len(X_feature.shape) == 2:\n",
    "            t, N = X_feature.shape\n",
    "            X_feature = X_feature.reshape((t, N, 1))\n",
    "\n",
    "        if len(X_feature_test.shape) == 2:\n",
    "            t, N = X_feature_test.shape\n",
    "            X_feature_test = X_feature_test.reshape((t, N, 1))\n",
    "\n",
    "        x_train_c, y_train_c, x_test_c, y_test_c = X_feature, y_feature, X_feature_test, y_feature_test\n",
    "        print('Utility Learning Sample: x_train %s y_train %s' %\n",
    "              (x_train_c.shape, y_train_c.shape))\n",
    "\n",
    "        self.model.fit(x_train_c, y_train_c, batch_size=batch_size, epochs=epoch,\n",
    "                       validation_data=(x_test_c, y_test_c), verbose=verbose, callbacks=callback)\n",
    "        results = self.model.evaluate(\n",
    "            x_test_c, y_test_c, batch_size=batch_size, verbose=1)\n",
    "        print(\"Test Loss\", results)\n",
    "\n",
    "        if save_name:\n",
    "            self.model.save_weights(save_name)\n",
    "\n",
    "    def predict(self, X_feature):\n",
    "        X_feature = np.array(X_feature)\n",
    "        if len(X_feature.shape) == 2:\n",
    "            t, N = X_feature.shape\n",
    "            X_feature = X_feature.reshape((t, N, 1))\n",
    "        return self.model.predict(X_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1dh1Ncy7Ub2"
   },
   "source": [
    "# IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4Ev7cbF17WxL"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "n_data = 15  # x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74Do-roa8JTF",
    "outputId": "c9c09496-1e58-4a2b-fcde-4710f3268d22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407407407407408"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svm_data_to_acc(x_train, y_train, x_val, y_val):\n",
    "    if len(set(y_train)) == 1:\n",
    "        return 0.5\n",
    "    classifier = sklearn.svm.SVC(C=1)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    return classifier.score(x_val, y_val)\n",
    "\n",
    "\n",
    "u_tot = svm_data_to_acc(x_train, y_train, x_test, y_test)\n",
    "u_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "GNJqZi2p8o_X"
   },
   "outputs": [],
   "source": [
    "utility_array = np.zeros(2**n_data)\n",
    "utility_array[0] = 0.5\n",
    "\n",
    "for v in range(1, 2**n_data):\n",
    "    # print(v)\n",
    "    ind = val_to_dataind(v)\n",
    "    utility_array[v] = svm_data_to_acc(x_train[ind], y_train[ind], x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "B2Lnsiuu9Kzx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "seed = 42\n",
    "(x_train, y_train), (x_test, y_test), utility_array = pickle.load( open('/Users/zhtian/PycharmProjects/DataValuation/iris_Seed{}_Ntrain{}_fix.data'.format(seed, n_data), 'rb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpLwYjDJ9YMZ"
   },
   "source": [
    "### Sample Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fewLkKPXAoTG"
   },
   "outputs": [],
   "source": [
    "X_feature_total = []\n",
    "y_feature_total = np.zeros(2**n_data)\n",
    "\n",
    "for v in range(2**n_data):\n",
    "    ind_bin = -np.ones(n_data)\n",
    "    ind = val_to_dataind(v)\n",
    "    ind_bin[ind] = 1\n",
    "    X_feature_total.append(ind_bin)\n",
    "    y_feature_total[v] = utility_array[v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f9oTBJ1wY8D"
   },
   "source": [
    "## Perm SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FVkVxSzOy55M"
   },
   "outputs": [],
   "source": [
    "true_sv = np.array([exact_shapley(utility_array, n_data, i) for i in range(n_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Acufxksswaks"
   },
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "\n",
    "X_feature, y_feature = [], []\n",
    "perm_sv = np.zeros(n_data)\n",
    "\n",
    "for i in range(n_data):\n",
    "    sv, x, y = perm_shapley_sampling(utility_array, n_data, 0, int(n_samples/n_data))\n",
    "    perm_sv[i] = sv\n",
    "    X_feature += x\n",
    "    y_feature += y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9vL-7A89YMb"
   },
   "source": [
    "### PermSV+DUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Learning Sample: x_train (1500, 15, 1) y_train (1500,)\n",
      "Train on 1500 samples, validate on 2000 samples\n",
      "Epoch 1/800\n",
      "1500/1500 [==============================] - 1s 939us/sample - loss: 0.0297 - val_loss: 0.0157\n",
      "Epoch 2/800\n",
      "1500/1500 [==============================] - 0s 223us/sample - loss: 0.0203 - val_loss: 0.0155\n",
      "Epoch 3/800\n",
      "1500/1500 [==============================] - 0s 220us/sample - loss: 0.0193 - val_loss: 0.0152\n",
      "Epoch 4/800\n",
      "1500/1500 [==============================] - 0s 220us/sample - loss: 0.0183 - val_loss: 0.0153\n",
      "Epoch 5/800\n",
      "1500/1500 [==============================] - 0s 220us/sample - loss: 0.0171 - val_loss: 0.0150\n",
      "Epoch 6/800\n",
      "1500/1500 [==============================] - 0s 222us/sample - loss: 0.0166 - val_loss: 0.0148\n",
      "Epoch 7/800\n",
      "1500/1500 [==============================] - 0s 222us/sample - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 8/800\n",
      "1500/1500 [==============================] - 0s 221us/sample - loss: 0.0160 - val_loss: 0.0144\n",
      "Epoch 9/800\n",
      "1500/1500 [==============================] - 0s 223us/sample - loss: 0.0151 - val_loss: 0.0142\n",
      "Epoch 10/800\n",
      "1500/1500 [==============================] - 0s 222us/sample - loss: 0.0152 - val_loss: 0.0142\n",
      "Epoch 11/800\n",
      "1500/1500 [==============================] - 0s 222us/sample - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 12/800\n",
      "1500/1500 [==============================] - 0s 220us/sample - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 13/800\n",
      "1500/1500 [==============================] - 0s 224us/sample - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 14/800\n",
      "1500/1500 [==============================] - 0s 237us/sample - loss: 0.0147 - val_loss: 0.0136\n",
      "Epoch 15/800\n",
      "1500/1500 [==============================] - 0s 230us/sample - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 16/800\n",
      "1500/1500 [==============================] - 0s 237us/sample - loss: 0.0141 - val_loss: 0.0132\n",
      "Epoch 17/800\n",
      "1500/1500 [==============================] - 0s 229us/sample - loss: 0.0132 - val_loss: 0.0123\n",
      "Epoch 18/800\n",
      "1500/1500 [==============================] - 0s 225us/sample - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 19/800\n",
      "1500/1500 [==============================] - 0s 224us/sample - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 20/800\n",
      "1500/1500 [==============================] - 0s 223us/sample - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 21/800\n",
      "1500/1500 [==============================] - 0s 223us/sample - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 22/800\n",
      "1500/1500 [==============================] - 0s 224us/sample - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 23/800\n",
      "1500/1500 [==============================] - 0s 228us/sample - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 24/800\n",
      "1500/1500 [==============================] - 0s 238us/sample - loss: 0.0121 - val_loss: 0.0115\n",
      "Epoch 25/800\n",
      "1500/1500 [==============================] - 0s 248us/sample - loss: 0.0122 - val_loss: 0.0115\n",
      "Epoch 26/800\n",
      "1500/1500 [==============================] - 0s 248us/sample - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 27/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 28/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 29/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 30/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 31/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 32/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 33/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 34/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 35/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 36/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 37/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 38/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 39/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 40/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 41/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 42/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 43/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 44/800\n",
      "1500/1500 [==============================] - 0s 250us/sample - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 45/800\n",
      "1500/1500 [==============================] - 0s 249us/sample - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 46/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 47/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 48/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 49/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 50/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 51/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 52/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 53/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 54/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 55/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0090 - val_loss: 0.0084\n",
      "Epoch 56/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 57/800\n",
      "1500/1500 [==============================] - 0s 248us/sample - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 58/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 59/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 60/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 61/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 62/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 63/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 64/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 65/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 66/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0090 - val_loss: 0.0077\n",
      "Epoch 67/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 68/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 69/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 70/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 71/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 72/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 73/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 74/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 75/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0082 - val_loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 77/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 78/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 79/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 80/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 81/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 82/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 83/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 84/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 85/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 86/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 87/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 88/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 89/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 90/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 91/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 92/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 93/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 94/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 95/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 96/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 97/800\n",
      "1500/1500 [==============================] - 0s 273us/sample - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 98/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 99/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 100/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 101/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 102/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 103/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 104/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 105/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 106/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 107/800\n",
      "1500/1500 [==============================] - 0s 244us/sample - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 108/800\n",
      "1500/1500 [==============================] - 0s 244us/sample - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 109/800\n",
      "1500/1500 [==============================] - 0s 245us/sample - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 110/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 111/800\n",
      "1500/1500 [==============================] - 0s 247us/sample - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 112/800\n",
      "1500/1500 [==============================] - 0s 250us/sample - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 113/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 114/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 115/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 116/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 117/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 118/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 119/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 120/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 121/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 122/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 123/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 124/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 125/800\n",
      "1500/1500 [==============================] - 0s 308us/sample - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 126/800\n",
      "1500/1500 [==============================] - 0s 326us/sample - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 127/800\n",
      "1500/1500 [==============================] - 0s 328us/sample - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 128/800\n",
      "1500/1500 [==============================] - 1s 367us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 129/800\n",
      "1500/1500 [==============================] - 1s 397us/sample - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 130/800\n",
      "1500/1500 [==============================] - 1s 381us/sample - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 131/800\n",
      "1500/1500 [==============================] - 1s 399us/sample - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 132/800\n",
      "1500/1500 [==============================] - 1s 417us/sample - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 133/800\n",
      "1500/1500 [==============================] - 1s 440us/sample - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 134/800\n",
      "1500/1500 [==============================] - 1s 471us/sample - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 135/800\n",
      "1500/1500 [==============================] - 1s 473us/sample - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 136/800\n",
      "1500/1500 [==============================] - 1s 530us/sample - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 137/800\n",
      "1500/1500 [==============================] - 1s 553us/sample - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 138/800\n",
      "1500/1500 [==============================] - 1s 572us/sample - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 139/800\n",
      "1500/1500 [==============================] - 1s 583us/sample - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 140/800\n",
      "1500/1500 [==============================] - 1s 606us/sample - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 141/800\n",
      "1500/1500 [==============================] - 1s 607us/sample - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 142/800\n",
      "1500/1500 [==============================] - 1s 609us/sample - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 143/800\n",
      "1500/1500 [==============================] - 1s 605us/sample - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 144/800\n",
      "1500/1500 [==============================] - 1s 604us/sample - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 145/800\n",
      "1500/1500 [==============================] - 1s 568us/sample - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 146/800\n",
      "1500/1500 [==============================] - 1s 541us/sample - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 147/800\n",
      "1500/1500 [==============================] - 1s 508us/sample - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 148/800\n",
      "1500/1500 [==============================] - 1s 472us/sample - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 149/800\n",
      "1500/1500 [==============================] - 1s 451us/sample - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 150/800\n",
      "1500/1500 [==============================] - 1s 428us/sample - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 151/800\n",
      "1500/1500 [==============================] - 1s 408us/sample - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 152/800\n",
      "1500/1500 [==============================] - 1s 390us/sample - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 153/800\n",
      "1500/1500 [==============================] - 1s 367us/sample - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 154/800\n",
      "1500/1500 [==============================] - 1s 355us/sample - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 155/800\n",
      "1500/1500 [==============================] - 1s 346us/sample - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 156/800\n",
      "1500/1500 [==============================] - 0s 325us/sample - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 157/800\n",
      "1500/1500 [==============================] - 0s 312us/sample - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 158/800\n",
      "1500/1500 [==============================] - 0s 302us/sample - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 159/800\n",
      "1500/1500 [==============================] - 0s 288us/sample - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 160/800\n",
      "1500/1500 [==============================] - 0s 286us/sample - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 161/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 162/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 163/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 164/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 165/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 166/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 167/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 168/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 169/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 170/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 171/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 172/800\n",
      "1500/1500 [==============================] - 0s 246us/sample - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 173/800\n",
      "1500/1500 [==============================] - 0s 250us/sample - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 174/800\n",
      "1500/1500 [==============================] - 0s 247us/sample - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 175/800\n",
      "1500/1500 [==============================] - 0s 246us/sample - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 176/800\n",
      "1500/1500 [==============================] - 0s 248us/sample - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 177/800\n",
      "1500/1500 [==============================] - 0s 250us/sample - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 178/800\n",
      "1500/1500 [==============================] - 0s 248us/sample - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 179/800\n",
      "1500/1500 [==============================] - 0s 246us/sample - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 180/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 181/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 182/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 183/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 184/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 185/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 186/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 187/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 188/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 189/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 190/800\n",
      "1500/1500 [==============================] - 0s 287us/sample - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 191/800\n",
      "1500/1500 [==============================] - 0s 286us/sample - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 192/800\n",
      "1500/1500 [==============================] - 0s 286us/sample - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 193/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 194/800\n",
      "1500/1500 [==============================] - 0s 286us/sample - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 195/800\n",
      "1500/1500 [==============================] - 0s 298us/sample - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 196/800\n",
      "1500/1500 [==============================] - 0s 300us/sample - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 197/800\n",
      "1500/1500 [==============================] - 0s 300us/sample - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 198/800\n",
      "1500/1500 [==============================] - 0s 305us/sample - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 199/800\n",
      "1500/1500 [==============================] - 0s 302us/sample - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 200/800\n",
      "1500/1500 [==============================] - 0s 306us/sample - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 201/800\n",
      "1500/1500 [==============================] - 0s 324us/sample - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 202/800\n",
      "1500/1500 [==============================] - 0s 318us/sample - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 203/800\n",
      "1500/1500 [==============================] - 0s 321us/sample - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 204/800\n",
      "1500/1500 [==============================] - 0s 315us/sample - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 205/800\n",
      "1500/1500 [==============================] - 0s 313us/sample - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 206/800\n",
      "1500/1500 [==============================] - 0s 314us/sample - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 207/800\n",
      "1500/1500 [==============================] - 0s 311us/sample - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 208/800\n",
      "1500/1500 [==============================] - 0s 312us/sample - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 209/800\n",
      "1500/1500 [==============================] - 0s 311us/sample - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 210/800\n",
      "1500/1500 [==============================] - 0s 312us/sample - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 211/800\n",
      "1500/1500 [==============================] - 0s 311us/sample - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 212/800\n",
      "1500/1500 [==============================] - 0s 311us/sample - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 213/800\n",
      "1500/1500 [==============================] - 0s 313us/sample - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 214/800\n",
      "1500/1500 [==============================] - 0s 311us/sample - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 215/800\n",
      "1500/1500 [==============================] - 0s 311us/sample - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 216/800\n",
      "1500/1500 [==============================] - 0s 310us/sample - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 217/800\n",
      "1500/1500 [==============================] - 0s 301us/sample - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 218/800\n",
      "1500/1500 [==============================] - 0s 301us/sample - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 219/800\n",
      "1500/1500 [==============================] - 0s 301us/sample - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 220/800\n",
      "1500/1500 [==============================] - 0s 298us/sample - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 221/800\n",
      "1500/1500 [==============================] - 0s 319us/sample - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 222/800\n",
      "1500/1500 [==============================] - 0s 295us/sample - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 223/800\n",
      "1500/1500 [==============================] - 0s 287us/sample - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 224/800\n",
      "1500/1500 [==============================] - 0s 289us/sample - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 225/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 226/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 292us/sample - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 227/800\n",
      "1500/1500 [==============================] - 0s 282us/sample - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 228/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 229/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 230/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 231/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 232/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 233/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 234/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 235/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 236/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 237/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 238/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 239/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 240/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 241/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 242/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 243/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 244/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 245/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 246/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 247/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 248/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 249/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 250/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 251/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 252/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 253/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 254/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 255/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 256/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 257/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 258/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 259/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 260/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 261/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 262/800\n",
      "1500/1500 [==============================] - 0s 273us/sample - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 263/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 264/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 265/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 266/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 267/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 268/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 269/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 270/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 271/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 272/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 273/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 274/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 275/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 276/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 277/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 278/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 279/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 280/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 281/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 282/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 283/800\n",
      "1500/1500 [==============================] - 0s 280us/sample - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 284/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 285/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 286/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 287/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 288/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 289/800\n",
      "1500/1500 [==============================] - 0s 283us/sample - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 290/800\n",
      "1500/1500 [==============================] - 0s 307us/sample - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 291/800\n",
      "1500/1500 [==============================] - 0s 284us/sample - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 292/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 293/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 294/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 295/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 296/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 297/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 298/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 299/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 300/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 301/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 302/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 303/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 304/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 305/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 306/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 307/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 308/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 309/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 310/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 311/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 312/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 313/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 314/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 315/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 316/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 317/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 318/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 319/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 320/800\n",
      "1500/1500 [==============================] - 0s 282us/sample - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 321/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 322/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 323/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 324/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 325/800\n",
      "1500/1500 [==============================] - 0s 283us/sample - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 326/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 327/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 328/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 329/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 330/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 331/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 332/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 333/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 334/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 335/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 336/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 337/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 338/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 339/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 340/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 341/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 342/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 343/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 344/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 345/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 346/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 347/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 348/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 349/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 350/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 351/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 352/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 353/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 354/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 355/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 356/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 357/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 358/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 359/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 360/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 361/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 362/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 363/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 364/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 365/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 366/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 367/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 368/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 369/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 370/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 371/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 372/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 373/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 374/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 375/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 376/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 377/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 378/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 379/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 380/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 381/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 382/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 383/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 384/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 385/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 386/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 387/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 388/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 389/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 390/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 391/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 392/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 393/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 394/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 395/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 396/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 397/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 398/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 399/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 400/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 401/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 402/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 403/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 404/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 405/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 406/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 407/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 408/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 409/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 410/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 411/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 412/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 413/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 414/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 415/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 416/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 417/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 418/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 419/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 420/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 421/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 422/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 423/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 424/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 425/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 426/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 427/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 428/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 429/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 430/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 431/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 432/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 433/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 434/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 435/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 436/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 437/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 438/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 439/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 440/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 441/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 442/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 443/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 444/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 445/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 446/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 447/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 448/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 449/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 450/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 451/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 452/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 453/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 454/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 455/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 456/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 457/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 458/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 459/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 460/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 461/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 462/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 463/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 464/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 465/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 466/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 467/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 468/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 469/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 470/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 471/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 472/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 473/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 474/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 475/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 476/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 477/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 478/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 479/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 480/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 481/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 482/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 483/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 484/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 485/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 486/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 487/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 488/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 489/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 490/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 491/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 492/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 493/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 494/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 495/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 496/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 497/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 498/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 499/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 500/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 501/800\n",
      "1500/1500 [==============================] - 0s 265us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 502/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 503/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 504/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 505/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 506/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 507/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 508/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 509/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 510/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 511/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 512/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 513/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 514/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 515/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 516/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 517/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 518/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 519/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 520/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 521/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 522/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 523/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 524/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 525/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 526/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 527/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 528/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 529/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 530/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 531/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 532/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 533/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 534/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 535/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 536/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 537/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 538/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 539/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 540/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 541/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 542/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 543/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 544/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 545/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 546/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 547/800\n",
      "1500/1500 [==============================] - 0s 250us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 548/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 549/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 550/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 551/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 552/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 553/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 554/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 555/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 556/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 557/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 558/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 559/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 560/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 561/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 562/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 563/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 564/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 565/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 566/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 567/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 568/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 569/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 570/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 571/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 572/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 573/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 574/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 575/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 576/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 577/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 578/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 579/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 580/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 581/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 582/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 583/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 584/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 585/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 586/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 587/800\n",
      "1500/1500 [==============================] - 0s 271us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 588/800\n",
      "1500/1500 [==============================] - 0s 282us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 589/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 590/800\n",
      "1500/1500 [==============================] - 0s 280us/sample - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 591/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 592/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 593/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 594/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 595/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 596/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 597/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 598/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 599/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 600/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 601/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 602/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 603/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 604/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 605/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 606/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 607/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 608/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 609/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 610/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 611/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 612/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 613/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 614/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 615/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 616/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 617/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 618/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 619/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 620/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 621/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 622/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 623/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 624/800\n",
      "1500/1500 [==============================] - 0s 298us/sample - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 625/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 626/800\n",
      "1500/1500 [==============================] - 0s 266us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 627/800\n",
      "1500/1500 [==============================] - 0s 292us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 628/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 629/800\n",
      "1500/1500 [==============================] - 0s 288us/sample - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 630/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 631/800\n",
      "1500/1500 [==============================] - 0s 296us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 632/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 633/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 634/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 635/800\n",
      "1500/1500 [==============================] - 0s 291us/sample - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 636/800\n",
      "1500/1500 [==============================] - 0s 302us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 637/800\n",
      "1500/1500 [==============================] - 0s 319us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 638/800\n",
      "1500/1500 [==============================] - 0s 286us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 639/800\n",
      "1500/1500 [==============================] - 0s 310us/sample - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 640/800\n",
      "1500/1500 [==============================] - 0s 303us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 641/800\n",
      "1500/1500 [==============================] - 0s 304us/sample - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 642/800\n",
      "1500/1500 [==============================] - 0s 316us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 643/800\n",
      "1500/1500 [==============================] - 0s 308us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 644/800\n",
      "1500/1500 [==============================] - 0s 312us/sample - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 645/800\n",
      "1500/1500 [==============================] - 0s 303us/sample - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 646/800\n",
      "1500/1500 [==============================] - 0s 330us/sample - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 647/800\n",
      "1500/1500 [==============================] - 0s 324us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 648/800\n",
      "1500/1500 [==============================] - 0s 309us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 649/800\n",
      "1500/1500 [==============================] - 0s 325us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 650/800\n",
      "1500/1500 [==============================] - 0s 326us/sample - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 651/800\n",
      "1500/1500 [==============================] - 0s 331us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 652/800\n",
      "1500/1500 [==============================] - 0s 326us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 653/800\n",
      "1500/1500 [==============================] - 0s 319us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 654/800\n",
      "1500/1500 [==============================] - 0s 315us/sample - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 655/800\n",
      "1500/1500 [==============================] - 0s 315us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 656/800\n",
      "1500/1500 [==============================] - 0s 310us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 657/800\n",
      "1500/1500 [==============================] - 0s 313us/sample - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 658/800\n",
      "1500/1500 [==============================] - 0s 299us/sample - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 659/800\n",
      "1500/1500 [==============================] - 0s 290us/sample - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 660/800\n",
      "1500/1500 [==============================] - 0s 308us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 661/800\n",
      "1500/1500 [==============================] - 0s 298us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 662/800\n",
      "1500/1500 [==============================] - 0s 297us/sample - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 663/800\n",
      "1500/1500 [==============================] - 0s 293us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 664/800\n",
      "1500/1500 [==============================] - 0s 292us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 665/800\n",
      "1500/1500 [==============================] - 0s 304us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 666/800\n",
      "1500/1500 [==============================] - 0s 315us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 667/800\n",
      "1500/1500 [==============================] - 0s 302us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 668/800\n",
      "1500/1500 [==============================] - 0s 300us/sample - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 669/800\n",
      "1500/1500 [==============================] - 0s 302us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 670/800\n",
      "1500/1500 [==============================] - 0s 304us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 671/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 672/800\n",
      "1500/1500 [==============================] - 0s 285us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 673/800\n",
      "1500/1500 [==============================] - 0s 278us/sample - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 674/800\n",
      "1500/1500 [==============================] - 0s 308us/sample - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 675/800\n",
      "1500/1500 [==============================] - 0s 275us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 676/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 282us/sample - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 677/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 678/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 679/800\n",
      "1500/1500 [==============================] - 0s 289us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 680/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 681/800\n",
      "1500/1500 [==============================] - 0s 277us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 682/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 683/800\n",
      "1500/1500 [==============================] - 0s 295us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 684/800\n",
      "1500/1500 [==============================] - 0s 293us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 685/800\n",
      "1500/1500 [==============================] - 0s 300us/sample - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 686/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 687/800\n",
      "1500/1500 [==============================] - 0s 280us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 688/800\n",
      "1500/1500 [==============================] - 0s 276us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 689/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 690/800\n",
      "1500/1500 [==============================] - 0s 282us/sample - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 691/800\n",
      "1500/1500 [==============================] - 0s 302us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 692/800\n",
      "1500/1500 [==============================] - 0s 291us/sample - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 693/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 694/800\n",
      "1500/1500 [==============================] - 0s 296us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 695/800\n",
      "1500/1500 [==============================] - 0s 315us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 696/800\n",
      "1500/1500 [==============================] - 0s 320us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 697/800\n",
      "1500/1500 [==============================] - 0s 319us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 698/800\n",
      "1500/1500 [==============================] - 0s 318us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 699/800\n",
      "1500/1500 [==============================] - 0s 274us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 700/800\n",
      "1500/1500 [==============================] - 0s 309us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 701/800\n",
      "1500/1500 [==============================] - 0s 298us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 702/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 703/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 704/800\n",
      "1500/1500 [==============================] - 0s 282us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 705/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 706/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 707/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 708/800\n",
      "1500/1500 [==============================] - 0s 280us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 709/800\n",
      "1500/1500 [==============================] - 0s 281us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 710/800\n",
      "1500/1500 [==============================] - 0s 279us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 711/800\n",
      "1500/1500 [==============================] - 0s 280us/sample - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 712/800\n",
      "1500/1500 [==============================] - 0s 283us/sample - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 713/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 714/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 715/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 716/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 717/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 718/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 719/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 720/800\n",
      "1500/1500 [==============================] - 0s 272us/sample - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 721/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 722/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 723/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 724/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 725/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 726/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 727/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 728/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 729/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 730/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 731/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 732/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 733/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 734/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 735/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 736/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 737/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 738/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 739/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 740/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 741/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 742/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 743/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 744/800\n",
      "1500/1500 [==============================] - 0s 256us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 745/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 746/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 747/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 748/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 749/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 750/800\n",
      "1500/1500 [==============================] - 0s 263us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 751/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 752/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 753/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 754/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 755/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 756/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 757/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 758/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 759/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 760/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 761/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 762/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 763/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 764/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 765/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 766/800\n",
      "1500/1500 [==============================] - 0s 270us/sample - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 767/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 768/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 769/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 770/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 771/800\n",
      "1500/1500 [==============================] - 0s 268us/sample - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 772/800\n",
      "1500/1500 [==============================] - 0s 269us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 773/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 774/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 775/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 776/800\n",
      "1500/1500 [==============================] - 0s 267us/sample - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 777/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 778/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 779/800\n",
      "1500/1500 [==============================] - 0s 264us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 780/800\n",
      "1500/1500 [==============================] - 0s 261us/sample - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 781/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 782/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 783/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 784/800\n",
      "1500/1500 [==============================] - 0s 262us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 785/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 786/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 787/800\n",
      "1500/1500 [==============================] - 0s 254us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 788/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 789/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 790/800\n",
      "1500/1500 [==============================] - 0s 255us/sample - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 791/800\n",
      "1500/1500 [==============================] - 0s 251us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 792/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 793/800\n",
      "1500/1500 [==============================] - 0s 258us/sample - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 794/800\n",
      "1500/1500 [==============================] - 0s 257us/sample - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 795/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 796/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 797/800\n",
      "1500/1500 [==============================] - 0s 260us/sample - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 798/800\n",
      "1500/1500 [==============================] - 0s 259us/sample - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 799/800\n",
      "1500/1500 [==============================] - 0s 252us/sample - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 800/800\n",
      "1500/1500 [==============================] - 0s 253us/sample - loss: 0.0050 - val_loss: 0.0036\n",
      "2000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 44us/sample - loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.003623871022835374\n"
     ]
    }
   ],
   "source": [
    "model = UtilityModel('mini-iris', load_name=None)\n",
    "\n",
    "ind = np.random.choice(len(y_feature_total), size=2000, replace=False)\n",
    "\n",
    "X_feature_test, y_feature_test = np.array(\n",
    "    X_feature_total)[ind], np.array(y_feature_total)[ind]\n",
    "\n",
    "model.fit(X_feature, y_feature, X_feature_test, y_feature_test,\n",
    "          lr=1e-3, save_name=None, verbose=1, epoch=600, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vP8kEsv-7x6"
   },
   "source": [
    "### Error Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qxJsuc2R-81C"
   },
   "outputs": [],
   "source": [
    "sampled_ind = [ int(dataind_to_val(((arr+1)/2).nonzero()[0])) for arr in X_feature ]\n",
    "\n",
    "learned_utility_array = model.predict(X_feature_total).reshape(-1)\n",
    "learned_utility_array[0:n_data+1] = utility_array[0:n_data+1]\n",
    "learned_utility_array[-1] = utility_array[-1]\n",
    "\n",
    "for v in sampled_ind:\n",
    "    learned_utility_array[v] = utility_array[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1CUnuyYl0P_-"
   },
   "outputs": [],
   "source": [
    "dnn_sv = np.array([exact_shapley(learned_utility_array, n_data, i) for i in range(n_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCb9i7cdASQo",
    "outputId": "2fe69a89-b769-4734-9c19-eb61bb4f6de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSet, L1 Error: 0.071\n",
      "Perm, L1 Error: 0.499\n",
      "DeepSet, L2 Error: 0.022\n",
      "Perm, L2 Error: 0.249\n",
      "DeepSet, Linf Error: 0.011\n",
      "Perm, Linf Error: 0.18\n"
     ]
    }
   ],
   "source": [
    "ord = 1\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-dnn_sv, ord=ord), 3))\n",
    "print('Perm, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-perm_sv, ord=ord), 3))\n",
    "# print('CGA, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-cga_sv, ord=ord), 3))\n",
    "\n",
    "ord = 2\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-dnn_sv, ord=ord), 3))\n",
    "print('Perm, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-perm_sv, ord=ord), 3))\n",
    "# print('CGA, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-cga_sv, ord=ord), 3))\n",
    "\n",
    "ord = np.inf\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-dnn_sv, ord=ord), 3))\n",
    "print('Perm, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-perm_sv, ord=ord), 3))\n",
    "# print('CGA, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-cga_sv, ord=ord), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx3w12SZ0aYF"
   },
   "source": [
    "## GroupSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "j5Ifjqwd2AvC"
   },
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "\n",
    "group_sv, X_feature, y_feature = grouptest_shapley_sampling(utility_array, n_data, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nR6R2AdK3wie"
   },
   "source": [
    "### GT+DUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HthCT-nr2Zc7",
    "outputId": "2e19ad9f-5df2-4de1-fde9-a64d3be9fa40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Learning Sample: x_train (1500, 15, 1) y_train (1500,)\n",
      "Epoch 1/800\n",
      "47/47 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0176\n",
      "Epoch 2/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0164\n",
      "Epoch 3/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0160\n",
      "Epoch 4/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 5/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 6/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0158\n",
      "Epoch 7/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 8/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0153\n",
      "Epoch 9/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 10/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 11/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 12/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 13/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 14/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 15/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0144\n",
      "Epoch 16/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 17/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 18/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 19/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 20/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 21/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 22/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 23/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 24/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 25/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0124\n",
      "Epoch 26/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 27/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 28/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 29/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0123\n",
      "Epoch 30/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0121\n",
      "Epoch 31/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0120\n",
      "Epoch 32/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 33/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 34/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 35/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 36/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 37/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 38/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 39/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 40/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 41/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 42/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 43/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 44/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 45/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 46/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 47/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 48/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 49/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 50/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 51/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0101\n",
      "Epoch 52/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 53/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 54/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 55/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 56/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 57/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 58/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 59/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 60/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 61/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 62/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 63/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 64/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 65/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0096\n",
      "Epoch 66/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 67/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 68/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0098\n",
      "Epoch 69/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 70/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 71/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 72/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 73/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 74/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 75/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0090\n",
      "Epoch 76/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 77/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 78/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0096\n",
      "Epoch 79/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 80/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 81/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 82/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 83/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0087\n",
      "Epoch 84/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0090\n",
      "Epoch 85/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 86/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 87/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0087\n",
      "Epoch 88/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0083\n",
      "Epoch 89/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0087\n",
      "Epoch 90/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 91/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 92/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 93/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 94/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 95/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0086\n",
      "Epoch 96/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 97/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 98/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 99/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 100/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0086\n",
      "Epoch 101/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 102/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0080\n",
      "Epoch 103/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 104/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 105/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 106/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 107/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 108/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 109/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 110/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 111/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 112/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 113/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 114/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 115/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 116/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 117/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 118/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 119/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 120/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 121/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 122/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 123/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0079\n",
      "Epoch 124/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0071\n",
      "Epoch 125/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 126/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 127/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 128/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 129/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 130/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 131/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 132/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 133/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 134/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 135/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 136/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 137/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 138/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 139/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 140/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 141/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 142/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 143/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 144/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 145/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 146/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 147/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 148/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 149/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 150/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 151/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 152/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 153/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 154/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 155/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 156/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 157/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 158/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 159/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 160/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 161/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 162/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 163/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 164/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 165/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 166/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 167/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 168/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 169/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 170/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 171/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 172/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 173/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 174/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 175/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 176/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 177/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 178/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 179/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 180/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 181/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 182/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 183/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 184/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 185/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 186/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 187/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 188/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 189/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 190/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 191/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 192/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 193/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 194/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 195/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 196/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 197/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 198/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 199/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 200/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 201/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 202/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 203/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 204/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 205/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 206/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 207/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 208/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 209/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 210/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 211/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 212/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 213/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 214/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 215/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 216/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 217/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 218/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 219/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 220/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 221/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 222/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 223/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 224/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 225/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 226/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 227/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 228/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 229/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 230/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 231/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 232/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 233/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 234/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 235/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 236/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 237/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 238/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 239/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 240/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 241/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 242/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 243/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 244/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 245/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 246/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 247/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 248/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 249/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 250/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 251/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 252/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 253/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 254/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 255/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 256/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 257/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 258/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 259/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 260/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 261/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 262/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 263/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 264/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 265/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 266/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 267/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 268/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 269/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 270/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 271/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 272/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 273/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 274/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 275/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 276/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 277/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 278/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 279/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 280/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 281/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 282/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 283/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 284/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 285/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 286/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 287/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 288/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 289/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 290/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 291/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 292/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 293/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 294/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 295/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 296/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 297/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 298/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 299/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 300/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 301/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 302/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 303/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 304/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 305/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 306/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 307/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 308/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 309/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 310/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 311/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 312/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 313/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 314/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 315/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 316/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 317/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 318/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 319/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 320/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 321/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 322/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 323/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 324/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 325/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 326/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 327/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 328/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 329/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 330/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 331/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 332/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 333/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 334/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 335/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 336/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 337/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 338/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 339/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 340/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 341/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 342/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 343/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 344/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 345/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 346/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 347/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 348/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 349/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 350/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 351/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 352/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 353/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 354/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 355/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 356/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 357/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 358/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 359/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 360/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 361/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 362/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 363/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 364/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 365/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 366/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 367/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 368/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 369/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 370/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 371/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 372/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 373/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 374/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 375/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 376/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 377/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 378/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 379/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 380/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 381/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 382/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 383/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 384/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 385/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 386/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 387/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 388/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 389/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 390/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 391/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 392/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 393/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 394/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 395/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 396/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 397/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 398/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 399/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 400/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 401/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 402/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 403/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 404/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 405/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 406/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 407/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 408/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 409/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 410/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 411/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 412/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 413/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 414/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 415/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 416/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 417/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 418/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 419/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 420/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 421/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 422/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 423/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 424/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 425/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 426/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 427/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 428/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 429/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 430/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 431/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 432/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 433/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 434/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 435/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 436/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 437/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 438/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 439/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 440/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 441/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 442/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 443/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 444/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 445/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 446/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 447/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 448/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 449/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 450/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 451/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 452/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 453/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 454/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 455/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 456/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 457/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 458/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 459/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 460/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 461/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 462/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 463/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 464/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 465/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 466/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 467/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 468/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 469/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 470/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 471/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 472/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 473/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 474/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 475/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 476/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 477/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 478/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 479/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 480/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 481/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 482/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 483/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 484/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 485/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 486/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 487/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 488/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 489/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 490/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 491/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 492/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 493/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 494/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 495/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 496/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 497/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 498/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 499/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 500/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 501/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 502/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 503/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 504/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 505/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 506/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 507/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 508/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 509/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 510/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 511/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 512/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 513/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 514/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 515/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 516/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 517/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 518/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 519/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 520/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 521/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 522/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 523/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 524/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 525/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 526/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 527/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 528/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 529/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 530/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 531/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 532/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 533/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 534/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 535/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 536/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 537/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 538/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 539/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 540/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 541/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 542/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 543/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 544/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 545/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 546/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 547/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 548/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 549/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 550/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 551/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 552/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 553/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 554/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 555/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 556/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 557/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 558/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 559/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 560/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 561/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 562/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 563/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 564/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 565/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 566/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 567/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 568/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 569/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 570/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 571/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 572/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 573/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 574/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 575/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 576/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 577/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 578/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 579/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 580/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 581/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 582/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 583/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 584/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 585/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 586/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 587/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 588/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 589/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 590/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 591/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 592/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 593/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 594/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 595/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 596/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 597/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 598/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 599/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 600/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 601/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 602/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 603/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 604/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 605/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 606/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 607/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 608/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 609/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 610/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 611/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 612/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 613/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 614/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 615/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 616/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 617/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 618/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 619/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 620/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 621/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 622/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 623/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 624/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 625/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 626/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 627/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 628/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 629/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 630/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 631/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 632/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 633/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 634/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 635/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 636/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 637/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 638/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 639/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 640/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 641/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 642/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 643/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 644/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 645/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 646/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 647/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 648/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 649/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 650/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 651/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 652/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 653/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 654/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 655/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 656/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 657/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 658/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 659/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 660/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 661/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 662/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 663/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 664/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 665/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 666/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 667/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 668/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 669/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 670/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 671/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 672/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 673/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 674/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 675/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 676/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 677/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 678/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 679/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 680/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 681/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 682/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 683/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 684/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 685/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 686/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 687/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 688/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 689/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 690/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 691/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 692/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 693/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 694/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 695/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 696/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 697/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 698/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 699/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 700/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 701/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 702/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 703/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 704/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 705/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 706/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 707/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 708/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 709/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 710/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 711/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 712/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 713/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 714/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 715/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 716/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 717/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 718/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 719/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 720/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 721/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 722/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 723/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 724/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 725/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 726/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 727/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 728/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 729/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 730/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 731/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 732/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 733/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 734/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 735/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 736/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 737/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 738/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 739/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 740/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 741/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 742/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 743/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 744/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 745/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 746/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 747/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 748/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 749/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 750/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 751/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 752/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 753/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 754/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 755/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 756/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 757/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 758/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 759/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 760/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 761/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 762/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 763/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 764/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 765/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 766/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 767/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 768/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 769/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 770/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 771/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 772/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 773/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 774/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 775/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 776/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 777/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 778/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 779/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 780/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 781/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 782/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 783/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 784/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 785/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 786/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 787/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 788/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 789/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 790/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 791/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 792/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 793/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 794/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 795/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 796/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 797/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 798/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 799/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 800/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Test Loss 0.004504920449107885\n"
     ]
    }
   ],
   "source": [
    "model = UtilityModel('mini-iris', load_name=None)\n",
    "\n",
    "model.fit(X_feature, y_feature, X_feature_test, y_feature_test, lr=1e-3, save_name=None, verbose=1, epoch=800, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCxT8kb42n8Z"
   },
   "source": [
    "### Error Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3aZlNqC12n8Z"
   },
   "outputs": [],
   "source": [
    "sampled_ind = [ int(dataind_to_val(((arr+1)/2).nonzero()[0])) for arr in X_feature ]\n",
    "\n",
    "learned_utility_array = model.predict(X_feature_total).reshape(-1)\n",
    "learned_utility_array[0:n_data+1] = utility_array[0:n_data+1]\n",
    "learned_utility_array[-1] = utility_array[-1]\n",
    "\n",
    "for v in sampled_ind:\n",
    "    learned_utility_array[v] = utility_array[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vSGFV77n2n8b"
   },
   "outputs": [],
   "source": [
    "dnn_sv = np.array([exact_shapley(learned_utility_array, n_data, i) for i in range(n_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6QlPVJ82n8c",
    "outputId": "a89785cb-e3bc-4d26-bb6d-0e98989a76ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSet, L1 Error: 0.066\n",
      "GT, L1 Error: 0.499\n",
      "DeepSet, L2 Error: 0.023\n",
      "GT, L2 Error: 0.249\n",
      "DeepSet, Linf Error: 0.011\n",
      "GT, Linf Error: 0.18\n"
     ]
    }
   ],
   "source": [
    "ord = 1\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-dnn_sv, ord=ord), 3))\n",
    "print('GT, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-perm_sv, ord=ord), 3))\n",
    "# print('CGA, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-cga_sv, ord=ord), 3))\n",
    "\n",
    "ord = 2\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-dnn_sv, ord=ord), 3))\n",
    "print('GT, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-perm_sv, ord=ord), 3))\n",
    "# print('CGA, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-cga_sv, ord=ord), 3))\n",
    "\n",
    "ord = np.inf\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-dnn_sv, ord=ord), 3))\n",
    "print('GT, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-perm_sv, ord=ord), 3))\n",
    "# print('CGA, L{} Error:'.format(ord), np.round(np.linalg.norm(true_sv-cga_sv, ord=ord), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dMb2Ipf1-oq"
   },
   "source": [
    "## Least Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "F1LAdZ8X3f3d"
   },
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "\n",
    "X_feature = []\n",
    "y_feature = np.zeros(n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    ind_bin = -np.ones(n_data)\n",
    "    v = np.random.choice(range(1, 2**n_data))\n",
    "    ind = val_to_dataind(v)\n",
    "    ind_bin[ind] = 1\n",
    "    X_feature.append(ind_bin)\n",
    "    y_feature[i] = utility_array[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOlnpmBu35SB",
    "outputId": "24237fc9-1ee6-4b03-830d-5f15f686299e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Learning Sample: x_train (1500, 15, 1) y_train (1500,)\n",
      "Epoch 1/800\n",
      "47/47 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0156\n",
      "Epoch 2/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0149\n",
      "Epoch 3/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0143\n",
      "Epoch 4/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0143\n",
      "Epoch 5/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0144\n",
      "Epoch 6/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0136\n",
      "Epoch 7/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 8/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0131\n",
      "Epoch 9/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "Epoch 10/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0126\n",
      "Epoch 11/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 12/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 13/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 14/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 15/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 16/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 17/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 18/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 19/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 20/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 21/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 22/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 23/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 24/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 25/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 26/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 27/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 28/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 29/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 30/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 31/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 32/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 33/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 34/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 35/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 36/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 37/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 38/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 39/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 40/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 41/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 42/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 43/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 44/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 45/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 46/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 47/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 48/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 49/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 50/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 51/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 52/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 53/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 54/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 55/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 56/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 57/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 58/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 59/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 60/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0067\n",
      "Epoch 61/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 62/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 63/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 64/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 65/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 66/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 67/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 68/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 69/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 70/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 71/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 72/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 73/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 74/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 75/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 76/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 77/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 78/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 79/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 80/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 81/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 82/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 83/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 84/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 85/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 86/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 87/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 88/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 89/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 90/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 91/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 92/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 93/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 94/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 95/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 96/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 97/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 98/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 99/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 100/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 101/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 102/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 103/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 104/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 105/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 106/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 107/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 108/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 109/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 110/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 111/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 112/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 113/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 114/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 115/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 116/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 117/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 118/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 119/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 120/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 121/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 122/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 123/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 124/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 125/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 126/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 127/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 128/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 129/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 130/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 131/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 132/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 133/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 134/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 135/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 136/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 137/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 138/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 139/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 140/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 141/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 142/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 143/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 144/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 145/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 146/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 147/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 148/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 149/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 150/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 151/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 152/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 153/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 154/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 155/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 156/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 157/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 158/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 159/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 160/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 161/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 162/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 163/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 164/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 165/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 166/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 167/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 168/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 169/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 170/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 171/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 172/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 173/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 174/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 175/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 176/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 177/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 178/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 179/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 180/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 181/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 182/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 183/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 184/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 185/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 186/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 187/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 188/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 189/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 190/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 191/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 192/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 193/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 194/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 195/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 196/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 197/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 198/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 199/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 200/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 201/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 202/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 203/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 204/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 205/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 206/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 207/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 208/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 209/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 210/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 211/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 212/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 213/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 214/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 215/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 216/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 217/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 218/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 219/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 220/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 221/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 222/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 223/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 224/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 225/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 226/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 227/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 228/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 229/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 230/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 231/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 232/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 233/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 234/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 235/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 236/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 237/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 238/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 239/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 240/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 241/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 242/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 243/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 244/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 245/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 246/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 247/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 248/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 249/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 250/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 251/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 252/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 253/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 254/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 255/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 256/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 257/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 258/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 259/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 260/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 261/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 262/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 263/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 264/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 265/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 266/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 267/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 268/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 269/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 270/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 271/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 272/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 273/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 274/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 275/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 276/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 277/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 278/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 279/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 280/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 281/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 282/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 283/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 284/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 285/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 286/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 287/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 288/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 289/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 290/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 291/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 292/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 293/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 294/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 295/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 296/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 297/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 298/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 299/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 300/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 301/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 302/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 303/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 304/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 305/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 306/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 307/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 308/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 309/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 310/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 311/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 312/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 313/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 314/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 315/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 316/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 317/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 318/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 319/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 320/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 321/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 322/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 323/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 324/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 325/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 326/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 327/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 328/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 329/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 330/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 331/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 332/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 333/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 334/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 335/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 336/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 337/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 338/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 339/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 340/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 341/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 342/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 343/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 344/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 345/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 346/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 347/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 348/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 349/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 350/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 351/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 352/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 353/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 354/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 355/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 356/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 357/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 358/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 359/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 360/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 361/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 362/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 363/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 364/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 365/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 366/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 367/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 368/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 369/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 370/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 371/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 372/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 373/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 374/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 375/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 376/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 377/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 378/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 379/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 380/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 381/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 382/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 383/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 384/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 385/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 386/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 387/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 388/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 389/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 390/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 391/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 392/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 393/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 394/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 395/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 396/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 397/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 398/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 399/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 400/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 401/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 402/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 403/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 404/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 405/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 406/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 407/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 408/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 409/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 410/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 411/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 412/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 413/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 414/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 415/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 416/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 417/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 418/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 419/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 420/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 421/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 422/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 423/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 424/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 425/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 426/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 427/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 428/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 429/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 430/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 431/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 432/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 433/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 434/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 435/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 436/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 437/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 438/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 439/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 440/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 441/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 442/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 443/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 444/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 445/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 446/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 447/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 448/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 449/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 450/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 451/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 452/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 453/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 454/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 455/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 456/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 457/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 458/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 459/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 460/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 461/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 462/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 463/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 464/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 465/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 466/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 467/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 468/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 469/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 470/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 471/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 472/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 473/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 474/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 475/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 476/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 477/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 478/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 479/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 480/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 481/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 482/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 483/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 484/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 485/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 486/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 487/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 488/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 489/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 490/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 491/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 492/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 493/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 494/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 495/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 496/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 497/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 498/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 499/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 500/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 501/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 502/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 503/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 504/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 505/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 506/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 507/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 508/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 509/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 510/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 511/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 512/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 513/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 514/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 515/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 516/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 517/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 518/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 519/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 520/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 521/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 522/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 523/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 524/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 525/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 526/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 527/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 528/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 529/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 530/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 531/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 532/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 533/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 534/800\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 535/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 536/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 537/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 538/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 539/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 540/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 541/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 542/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 543/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 544/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 545/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 546/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 547/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 548/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 549/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 550/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 551/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 552/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 553/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 554/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 555/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 556/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 557/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 558/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 559/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 560/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 561/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 562/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 563/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 564/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 565/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 566/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 567/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 568/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 569/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 570/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 571/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 572/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 573/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 574/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 575/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 576/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 577/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 578/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 579/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 580/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 581/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 582/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 583/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 584/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 585/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 586/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 587/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 588/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 589/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 590/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 591/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 592/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 593/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 594/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 595/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 596/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 597/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 598/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 599/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 600/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 601/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 602/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 603/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 604/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 605/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 606/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 607/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 608/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 609/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 610/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 611/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 612/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 613/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 614/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 615/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 616/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 617/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 618/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 619/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 620/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 621/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 622/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 623/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 624/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 625/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 626/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 627/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 628/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 629/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 630/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 631/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 632/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 633/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 634/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 635/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 636/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 637/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 638/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 639/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 640/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 641/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 642/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 643/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 644/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 645/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 646/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 647/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 648/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 649/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 650/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 651/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 652/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 653/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 654/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 655/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 656/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 657/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 658/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 659/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 660/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 661/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 662/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 663/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 664/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 665/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 666/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 667/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 668/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 669/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 670/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 671/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 672/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 673/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 674/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 675/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 676/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 677/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 678/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 679/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 680/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 681/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 682/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 683/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 684/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 685/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 686/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 687/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 688/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 689/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 690/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 691/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 692/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 693/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 694/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 695/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 696/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 697/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 698/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 699/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 700/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 701/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 702/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 703/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 704/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 705/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 706/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 707/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 708/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 709/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 710/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 711/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 712/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 713/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 714/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 715/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 716/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 717/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 718/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 719/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 720/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 721/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 722/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 723/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 724/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 725/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 726/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 727/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 728/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 729/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 730/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 731/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 732/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 733/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 734/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 735/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 736/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 737/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 738/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 739/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 740/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 741/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 742/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 743/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 744/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 745/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 746/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 747/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 748/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 749/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 750/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 751/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 752/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 753/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 754/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 755/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 756/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 757/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 758/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 759/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 760/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 761/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 762/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 763/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 764/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 765/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 766/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 767/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 768/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 769/800\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 770/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 771/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 772/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 773/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 774/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 775/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 776/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 777/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 778/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 779/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 780/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 781/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 782/800\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 783/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 784/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 785/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 786/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 787/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 788/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 789/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 790/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 791/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 792/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 793/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 794/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 795/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 796/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 797/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 798/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 799/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 800/800\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Test Loss 0.00252999784424901\n"
     ]
    }
   ],
   "source": [
    "model = UtilityModel('mini-iris', load_name=None)\n",
    "\n",
    "model.fit(X_feature, y_feature, X_feature_test, y_feature_test, lr=1e-3, save_name=None, verbose=1, epoch=800, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "oybXd4bw4YnD"
   },
   "outputs": [],
   "source": [
    "sampled_ind = [int(dataind_to_val(((arr+1)/2).nonzero()[0]))\n",
    "               for arr in X_feature]\n",
    "\n",
    "learned_utility_array = model.predict(X_feature_total).reshape(-1)\n",
    "learned_utility_array[0:n_data+1] = utility_array[0:n_data+1]\n",
    "learned_utility_array[-1] = utility_array[-1]\n",
    "\n",
    "for v in sampled_ind:\n",
    "    learned_utility_array[v] = utility_array[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94ON8NCd3tvJ",
    "outputId": "76f20229-7361-4912-b23d-975e1982b50e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal\n",
      "unknown\n",
      "optimal\n",
      "unknown\n",
      "Total Constraints: 32768, Satisfy: 32718, Accuracy: 0.99847412109375\n",
      "optimal\n",
      "unknown\n",
      "Total Constraints: 32768, Satisfy: 32738, Accuracy: 0.99908447265625\n"
     ]
    }
   ],
   "source": [
    "u_tot = utility_array[-1]\n",
    "true_lc, true_e = ComputeLC(X_feature_total, y_feature_total, u_tot)\n",
    "true_lc = ComputeLC_Normalize(X_feature_total, y_feature_total, u_tot, true_e)\n",
    "\n",
    "dnn_lc, dnn_e = ComputeLC(X_feature_total, np.float64(learned_utility_array), u_tot)\n",
    "dnn_lc = ComputeLC_Normalize(X_feature_total, np.float64(learned_utility_array), u_tot, dnn_e)\n",
    "checkConstraint(X_feature_total, dnn_lc, true_e, y_feature_total)\n",
    "\n",
    "sample_lc, sample_e = ComputeLC(X_feature, y_feature, u_tot)\n",
    "sample_lc = ComputeLC_Normalize(X_feature, y_feature, u_tot, sample_e)\n",
    "checkConstraint(X_feature_total, sample_lc, true_e, y_feature_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjl_FaA6OrD-",
    "outputId": "705616bd-11c5-4997-f3b6-b0803b3feace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSet, L1 Error: 0.17\n",
      "MC, L1 Error: 0.48\n",
      "DeepSet, L2 Error: 0.061\n",
      "MC, L2 Error: 0.163\n",
      "DeepSet, Linf Error: 0.042\n",
      "MC, Linf Error: 0.082\n"
     ]
    }
   ],
   "source": [
    "ord = 1\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_lc-dnn_lc, ord=ord), 3))\n",
    "print('MC, L{} Error:'.format(ord), np.round(np.linalg.norm(true_lc-sample_lc, ord=ord), 3))\n",
    "\n",
    "ord = 2\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_lc-dnn_lc, ord=ord), 3))\n",
    "print('MC, L{} Error:'.format(ord), np.round(np.linalg.norm(true_lc-sample_lc, ord=ord), 3))\n",
    "\n",
    "ord = np.inf\n",
    "print('DeepSet, L{} Error:'.format(ord), np.round(np.linalg.norm(true_lc-dnn_lc, ord=ord), 3))\n",
    "print('MC, L{} Error:'.format(ord), np.round(np.linalg.norm(true_lc-sample_lc, ord=ord), 3))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "data-valuation-release.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
